{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3cae6c87",
   "metadata": {},
   "source": [
    "### Reading pickled files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "373af188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Arguments:\n",
      "  outputDir: C:\\Users\\sargs\\OneDrive\\Desktop\\ECE C143A\\neural_seq_decoder\\logs\\speech_logs\\speechBaseline4\n",
      "  datasetPath: C:\\Users\\sargs\\OneDrive\\Desktop\\ECE C143A\\neural_seq_decoder\\data\\ptDecoder_ctc.pkl\n",
      "  seqLen: 150\n",
      "  maxTimeSeriesLen: 1200\n",
      "  batchSize: 128\n",
      "  lrStart: 0.05\n",
      "  lrEnd: 0.02\n",
      "  nUnits: 384\n",
      "  nBatch: 10000\n",
      "  nLayers: 5\n",
      "  seed: 0\n",
      "  nClasses: 40\n",
      "  nInputFeatures: 256\n",
      "  dropout: 0.2\n",
      "  whiteNoiseSD: 1.0\n",
      "  constantOffsetSD: 0.3\n",
      "  gaussianSmoothWidth: 2.0\n",
      "  strideLen: 4\n",
      "  kernelLen: 32\n",
      "  bidirectional: True\n",
      "  l2_decay: 1e-05\n",
      "  post_gru_num_layers: 2\n",
      "  post_gru_dropout: 0.2\n",
      "  gradient_clip: 1.0\n",
      "  use_warmup_cosine: True\n",
      "  warmup_batches: 500\n",
      "\n",
      "Training Statistics:\n",
      "  Test Loss: [6.77241135 2.90256718 2.50528853 2.08744676 1.79987253 1.59069293\n",
      " 1.43458639 1.34363924 1.26879133 1.19619846 1.16290774 1.11585093\n",
      " 1.07727977 1.05455998 1.00927448 1.00691632 0.96868515 0.96153566\n",
      " 0.93431936 0.93373442 0.91170577 0.8921643  0.8880184  0.88049412\n",
      " 0.86942509 0.84712676 0.86244617 0.8433966  0.84028775 0.82976191\n",
      " 0.82048818 0.81503405 0.82074322 0.80882502 0.82093818 0.8224909\n",
      " 0.80139446 0.81316383 0.80850015 0.80238322 0.7949026  0.79619176\n",
      " 0.77883884 0.79354061 0.79738406 0.80156381 0.80023425 0.79824489\n",
      " 0.80444976 0.79744482 0.81263297 0.79522296 0.80453491 0.79607405\n",
      " 0.81442588 0.80448001 0.79988984 0.80775411 0.82617862 0.81933716\n",
      " 0.81506688 0.81957626 0.81882143 0.8206311  0.82830238 0.82325329\n",
      " 0.82592228 0.82385295 0.81688023 0.83021682 0.82982949 0.82586357\n",
      " 0.84161193 0.83368874 0.83922522 0.84112488 0.85033587 0.84569836\n",
      " 0.84889398 0.85689231 0.85256904 0.85373926 0.85015535 0.8503937\n",
      " 0.84839637 0.86288943 0.84995876 0.85195596 0.86492041 0.86295537\n",
      " 0.86217036 0.87978608 0.85875498 0.87254906 0.8705943  0.87744665\n",
      " 0.87265866 0.86882768 0.87268693 0.87502214]\n",
      "  Test CER: [0.91102307 0.9535306  0.81127481 0.64293673 0.53765837 0.45429409\n",
      " 0.40712311 0.38256779 0.36061244 0.34138088 0.33543808 0.32074615\n",
      " 0.30985102 0.30048285 0.29350832 0.29016549 0.28001321 0.27539103\n",
      " 0.26647683 0.26602286 0.25995625 0.25442615 0.25067063 0.25021666\n",
      " 0.24241674 0.23795964 0.23874376 0.23346127 0.23552474 0.23053114\n",
      " 0.22487722 0.22475342 0.22520738 0.22157567 0.22062647 0.22013124\n",
      " 0.21592175 0.21876935 0.21055672 0.2141059  0.21026784 0.21216623\n",
      " 0.20576947 0.20642978 0.2072139  0.20746152 0.20449012 0.20337584\n",
      " 0.20391234 0.20201395 0.20316949 0.20044571 0.20155999 0.19953778\n",
      " 0.19879493 0.19656638 0.19908382 0.19508068 0.19986794 0.19739177\n",
      " 0.19545211 0.19685527 0.19503941 0.19409022 0.19499814 0.19351244\n",
      " 0.19177913 0.19578226 0.19210928 0.19392514 0.19392514 0.19120135\n",
      " 0.19239817 0.19082993 0.1908712  0.19008708 0.19041723 0.19004581\n",
      " 0.18893153 0.19054104 0.19021089 0.18822995 0.19082993 0.18926169\n",
      " 0.18876646 0.18926169 0.19025216 0.189922   0.18798234 0.18872519\n",
      " 0.1874871  0.18856011 0.18517601 0.1893855  0.18736329 0.18662044\n",
      " 0.18723949 0.18645537 0.18666171 0.18674425]\n",
      "  Number of evaluations: 100\n",
      "\n",
      "Model Weights:\n",
      "  Number of parameter groups: 101\n",
      "  Parameter keys: ['dayWeights', 'dayBias', 'gaussianSmoother.weight', 'gru_decoder.weight_ih_l0', 'gru_decoder.weight_hh_l0']...\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Path to your log directory\n",
    "log_dir = r\"C:\\Users\\sargs\\OneDrive\\Desktop\\ECE C143A\\neural_seq_decoder\\logs\\speech_logs\\speechBaseline4\"\n",
    "\n",
    "# Read training arguments\n",
    "with open(f\"{log_dir}/args\", \"rb\") as f:\n",
    "    args = pickle.load(f)\n",
    "print(\"Training Arguments:\")\n",
    "for key, value in args.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# Read training statistics\n",
    "with open(f\"{log_dir}/trainingStats\", \"rb\") as f:\n",
    "    stats = pickle.load(f)\n",
    "print(\"\\nTraining Statistics:\")\n",
    "print(f\"  Test Loss: {stats['testLoss']}\")\n",
    "print(f\"  Test CER: {stats['testCER']}\")\n",
    "print(f\"  Number of evaluations: {len(stats['testLoss'])}\")\n",
    "\n",
    "# Check model weights (just metadata, not the full weights)\n",
    "model_weights_path = f\"{log_dir}/modelWeights\"\n",
    "weights = torch.load(model_weights_path, map_location='cpu')\n",
    "print(f\"\\nModel Weights:\")\n",
    "print(f\"  Number of parameter groups: {len(weights)}\")\n",
    "print(f\"  Parameter keys: {list(weights.keys())[:5]}...\")  # Show first 5 keys"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
